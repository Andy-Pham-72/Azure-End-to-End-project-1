{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"92d52c3b-39bb-45ae-a4de-b6716bdb55e3","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["import os\n","import json\n","import pandas as pd\n","from pathlib import Path\n","\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DecimalType\n","import decimal\n","import logging"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"39308161-9eca-422e-b634-15ca443bc6e7","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["container_name = \"#####\"\n","storage_name = \"#####\"\n","mount_dir = \"/data\"\n","key = \"#####\""]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9b8f79f4-385e-4592-b178-776109a748e6","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"},{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n","<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n","<span class=\"ansi-green-fg\">&lt;command-2211900603944736&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n","<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> \n","<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> \n","<span class=\"ansi-green-fg\">----&gt; 7</span><span class=\"ansi-red-fg\"> dbutils.fs.mount(\n","</span><span class=\"ansi-green-intense-fg ansi-bold\">      8</span>   source <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;wasbs://%s@%s.blob.core.windows.net&#34;</span> <span class=\"ansi-blue-fg\">%</span><span class=\"ansi-blue-fg\">(</span>container_name<span class=\"ansi-blue-fg\">,</span> storage_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span>\n","<span class=\"ansi-green-intense-fg ansi-bold\">      9</span>   mount_point <span class=\"ansi-blue-fg\">=</span> mount_dir<span class=\"ansi-blue-fg\">,</span>\n","\n","<span class=\"ansi-green-fg\">/databricks/python_shell/dbruntime/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n","<span class=\"ansi-green-intense-fg ansi-bold\">    379</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n","<span class=\"ansi-green-intense-fg ansi-bold\">    380</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n","<span class=\"ansi-green-fg\">--&gt; 381</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n","<span class=\"ansi-green-intense-fg ansi-bold\">    382</span> \n","<span class=\"ansi-green-intense-fg ansi-bold\">    383</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n","\n","<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling o316.mount.\n",": java.rmi.RemoteException: java.lang.IllegalArgumentException: Mount point &#39;/data&#39; must be within &#39;/mnt&#39;; nested exception is: \n","\tjava.lang.IllegalArgumentException: Mount point &#39;/data&#39; must be within &#39;/mnt&#39;\n","\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:128)\n","\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:68)\n","\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:739)\n","\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n","\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n","\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.lang.reflect.Method.invoke(Method.java:498)\n","\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n","\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n","\tat py4j.Gateway.invoke(Gateway.java:295)\n","\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n","\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n","\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n","\tat java.lang.Thread.run(Thread.java:748)\n","Caused by: java.lang.IllegalArgumentException: Mount point &#39;/data&#39; must be within &#39;/mnt&#39;\n","\tat com.databricks.backend.daemon.data.common.MountConf.ensureMountPointValid(MountConf.scala:80)\n","\tat com.databricks.backend.daemon.data.common.MountConf.ensureMountPointValid$(MountConf.scala:59)\n","\tat com.databricks.backend.daemon.data.server.DataDaemonConf.ensureMountPointValid(DataDaemonConf.scala:19)\n","\tat com.databricks.backend.daemon.data.server.util.MountEntry$.fromDbfsMountPoint(MountEntry.scala:248)\n","\tat com.databricks.backend.daemon.data.server.handler.MountHandler.validateMountRequest(MountHandler.scala:56)\n","\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:95)\n","\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:97)\n","\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:96)\n","\tat scala.collection.immutable.List.foreach(List.scala:431)\n","\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:96)\n","\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:300)\n","\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:259)\n","\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:90)\n","\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:117)\n","\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:117)\n","\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:75)\n","\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:346)\n","\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:440)\n","\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:460)\n","\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:213)\n","\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n","\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\n","\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:211)\n","\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:208)\n","\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:18)\n","\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:256)\n","\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:241)\n","\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:18)\n","\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:435)\n","\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:355)\n","\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:18)\n","\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:346)\n","\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:318)\n","\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:18)\n","\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:74)\n","\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:876)\n","\tat scala.util.Try$.apply(Try.scala:213)\n","\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:876)\n","\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:797)\n","\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:458)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:213)\n","\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n","\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\n","\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:211)\n","\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:208)\n","\tat com.databricks.rpc.JettyServer$.withAttributionContext(JettyServer.scala:237)\n","\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:256)\n","\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:241)\n","\tat com.databricks.rpc.JettyServer$.withAttributionTags(JettyServer.scala:237)\n","\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:432)\n","\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:357)\n","\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n","\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n","\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n","\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n","\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n","\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n","\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n","\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n","\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n","\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n","\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n","\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n","\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n","\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n","\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n","\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n","\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n","\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n","\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n","\t... 1 more\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2211900603944736&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> \n<span class=\"ansi-green-fg\">----&gt; 7</span><span class=\"ansi-red-fg\"> dbutils.fs.mount(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      8</span>   source <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;wasbs://%s@%s.blob.core.windows.net&#34;</span> <span class=\"ansi-blue-fg\">%</span><span class=\"ansi-blue-fg\">(</span>container_name<span class=\"ansi-blue-fg\">,</span> storage_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      9</span>   mount_point <span class=\"ansi-blue-fg\">=</span> mount_dir<span class=\"ansi-blue-fg\">,</span>\n\n<span class=\"ansi-green-fg\">/databricks/python_shell/dbruntime/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    379</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    380</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-fg\">--&gt; 381</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n<span class=\"ansi-green-intense-fg ansi-bold\">    382</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    383</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n\n<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling o316.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: Mount point &#39;/data&#39; must be within &#39;/mnt&#39;; nested exception is: \n\tjava.lang.IllegalArgumentException: Mount point &#39;/data&#39; must be within &#39;/mnt&#39;\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:128)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:68)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:739)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: Mount point &#39;/data&#39; must be within &#39;/mnt&#39;\n\tat com.databricks.backend.daemon.data.common.MountConf.ensureMountPointValid(MountConf.scala:80)\n\tat com.databricks.backend.daemon.data.common.MountConf.ensureMountPointValid$(MountConf.scala:59)\n\tat com.databricks.backend.daemon.data.server.DataDaemonConf.ensureMountPointValid(DataDaemonConf.scala:19)\n\tat com.databricks.backend.daemon.data.server.util.MountEntry$.fromDbfsMountPoint(MountEntry.scala:248)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.validateMountRequest(MountHandler.scala:56)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:95)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:97)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:96)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:96)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:300)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:259)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:90)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:117)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:117)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:75)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:346)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:440)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:460)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:213)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:211)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:208)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:18)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:256)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:241)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:18)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:435)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:355)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:18)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:346)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:318)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:18)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:74)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:876)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:876)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:797)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:458)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:213)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:211)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:208)\n\tat com.databricks.rpc.JettyServer$.withAttributionContext(JettyServer.scala:237)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:256)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:241)\n\tat com.databricks.rpc.JettyServer$.withAttributionTags(JettyServer.scala:237)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:432)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:357)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\t... 1 more\n</div>","errorSummary":"java.rmi.RemoteException: java.lang.IllegalArgumentException: Mount point &#39;/data&#39; must be within &#39;/mnt&#39;; nested exception is: ","errorTraceType":"html","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["\n","\n","output_container_path = \"wasbs://%s@%s.blob.core.windows.net\" % (output_container_name, storage_name)\n","\n","dbutils.fs.mount(\n","  source = output_container_path,\n","  mount_point = mount_dir,\n","  extra_configs = {\"fs.azure.sas.%s.%s.blob.core.windows.net\" % (container_name, storage_name): key })"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9284aee8-3cfd-49e1-ab9d-6b147517d699","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# A set of functions\n","\n","def parse_csv(line):\n","    \"\"\"\n","   This function will parse \".txt\" file from blob storage.\n","\n","   since we are working with comma-separated values file so we want to return event object\n","\n","   :param line: A line of \".txt\" file in CSV format.\n","   :return: Common event object.\n","   \"\"\"\n","    try:\n","        record_type_pos = 2 # filter for \"Q\" or \"T\" value\n","        record = line.split(\",\")\n","        # Filter by record_type (T = Trade or Q = Quote):\n","        if record[record_type_pos] == \"T\":\n","            # Create event object by using values from record object and performing data type conversion\n","            event = [record[0], # trade_dt\n","                     record[1], # file_tm\n","                     record[2], # event_type\n","                     record[3], # symbol\n","                     record[4], # event_tm\n","                     int(record[5]), # event_seq_nb\n","                     record[6],   # exchange\n","                     decimal.Decimal(record[7]), # bid_pr\n","                     int(record[8]), # bid_size\n","                     None, None,\n","                     \"T\"]\n","            return event\n","        elif record[record_type_pos] == \"Q\":\n","            event = [record[0], \n","                     record[1], \n","                     record[2], \n","                     record[3], \n","                     record[4], \n","                     int(record[5]), \n","                     record[6],\n","                     decimal.Decimal(record[7]), \n","                     int(record[8]), \n","                     decimal.Decimal(record[9]), # ask_pr\n","                     int(record[10]),            # ask_size\n","                     \"Q\"]\n","            return event\n","    except Exception as e:\n","        # Return exception as \"Bad record\" and convert values to None preceding record_type == \"B\"\n","        event = [None, None, None, None, None, None, None, None, None, None, None, \"B\"]\n","        logging.error(\"Bad record\", e)\n","        # print(f\"Bad record: {e}\")\n","        return event\n","    \n","def parse_json(line):\n","    \"\"\"\n","    This function will parse through each line in the JSON formatted \".txt\" file stored from blob storage.\n","\n","    :param line: Each line of \".txt\" file in JSON format.\n","    :return: common_event() object\n","    \"\"\"\n","    try:\n","        record = json.loads(line)\n","        record_type = record[\"event_type\"]\n","        # Parse records for each type and convert data type as necessary\n","        # Filter by record_type (T = Trade or Q = Quote):\n","        if record_type == \"T\":\n","            # Create event object based and\n","            event = [record[\"trade_dt\"], \n","                     record[\"file_tm\"], \n","                     record[\"event_type\"], \n","                     record[\"symbol\"],\n","                     record[\"event_tm\"], \n","                     int(record[\"event_seq_nb\"]), \n","                     record[\"exchange\"],\n","                     decimal.Decimal(record[\"bid_pr\"]), \n","                     int(record[\"bid_size\"]), \n","                     None, None, # Try place None values\n","                     \"T\"]\n","            return event\n","        elif record_type == \"Q\":\n","            event = [record[\"trade_dt\"], \n","                     record[\"file_tm\"], \n","                     record[\"event_type\"], \n","                     record[\"symbol\"],\n","                     record[\"event_tm\"], \n","                     int(record[\"event_seq_nb\"]), \n","                     record[\"exchange\"],\n","                     decimal.Decimal(record[\"bid_pr\"]), \n","                     int(record[\"bid_size\"]), \n","                     decimal.Decimal(record[\"ask_pr\"]),\n","                     int(record[\"ask_size\"]), \n","                     \"Q\"]\n","            return event\n","    except Exception as e:\n","        # Return exception as \"Bad record\" and convert values to None preceding record_type == \"B\"\n","        event = [None, None, None, None, None, None, None, None, None, None, None, \"B\"]\n","        logging.error(\"Bad record\", e)\n","        # print(f\"Bad record: {e}\")\n","        return event"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6bb59b17-162a-4847-abc0-035bcd7004c6","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Initialize schema\n","\n","commonEventSchema = StructType([\n","            StructField(\"trade_dt\", StringType(), True),\n","            StructField(\"file_tm\", StringType(), True),\n","            StructField(\"record_type\", StringType(), True),\n","            StructField(\"symbol\", StringType(), True),\n","            StructField(\"event_tm\", StringType(), True),\n","            StructField(\"event_seq_nb\", IntegerType(), True),\n","            StructField(\"trade_pr\", StringType(), True),\n","            StructField(\"bid_pr\", DecimalType(), True),\n","            StructField(\"bid_size\", IntegerType(), True),\n","            StructField(\"ask_pr\", DecimalType(), True),\n","            StructField(\"ask_size\", IntegerType(), True),\n","            StructField(\"partition\", StringType(), True)\n","\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"cdefebf9-ef06-45ea-8c16-9f8c6e5bca6a","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">Out[6]: DataFrame[trade_dt: string, file_tm: string, record_type: string, symbol: string, event_tm: string, event_seq_nb: int, trade_pr: string, bid_pr: decimal(10,0), bid_size: int, ask_pr: decimal(10,0), ask_size: int, partition: string]</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">Out[6]: DataFrame[trade_dt: string, file_tm: string, record_type: string, symbol: string, event_tm: string, event_seq_nb: int, trade_pr: string, bid_pr: decimal(10,0), bid_size: int, ask_pr: decimal(10,0), ask_size: int, partition: string]</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# csv path\n","csv_dir_1 = \"/data/csv/2020-08-05/NYSE/part-00000-5e4ced0a-66e2-442a-b020-347d0df4df8f-c000.txt\"\n","csv_dir_2 = \"/data/csv/2020-08-06/NYSE/part-00000-214fff0a-f408-466c-bb15-095cd8b648dc-c000.txt\"\n","\n","json_dir_1 = \"/data/json/2020-08-05/NASDAQ/part-00000-c6c48831-3d45-4887-ba5f-82060885fc6c-c000.txt\"\n","json_dir_2 = \"/data/json/2020-08-06/NASDAQ/part-00000-092ec1db-39ab-4079-9580-f7c7b516a283-c000.txt\"\n","\n","\n","# Create Spark Session\n","spark = SparkSession.builder.master('local').appName('app').getOrCreate()\n","\n","spark.conf.set(\n","        \"fs.azure.account.key.%s.blob.core.windows.net\" % (storage_name), \n","         key\n",")\n","\n","# Initilize spark context\n","sc = spark.sparkContext\n","\n","# Raw text files\n","raw_csv_1 = sc.textFile( \"wasbs://%s@%s.blob.core.windows.net%s\" %( container_name, storage_name, csv_dir_1))\n","\n","raw_csv_2 = sc.textFile( \"wasbs://%s@%s.blob.core.windows.net%s\" %( container_name, storage_name, csv_dir_2))\n","\n","raw_json_1 = sc.textFile( \"wasbs://%s@%s.blob.core.windows.net%s\" %( container_name, storage_name, json_dir_1))\n","\n","raw_json_2 =  sc.textFile( \"wasbs://%s@%s.blob.core.windows.net%s\" %( container_name, storage_name, json_dir_2))\n","\n","# Parsed files\n","parsed_csv1 = raw_csv_1.map(lambda line: parse_csv(line))\n","parsed_csv2 = raw_csv_2.map(lambda line: parse_csv(line))\n","\n","parsed_json1= raw_json_1.map(lambda line: parse_json(line))\n","parsed_json2= raw_json_2.map(lambda line: parse_json(line))\n","\n","spark_df1 = spark.createDataFrame(parsed_csv1, commonEventSchema)\n","spark_df2 = spark.createDataFrame(parsed_csv2, commonEventSchema)\n","spark_df3 = spark.createDataFrame(parsed_json1, commonEventSchema)\n","spark_df4 = spark.createDataFrame(parsed_json2, commonEventSchema)\n","\n","spark_df1"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"29d9af4a-ea1a-49a3-838e-0d10556873c5","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">+----------+--------------------+-----------+------+--------------------+------------+--------+------+--------+------+--------+---------+\n","  trade_dt|             file_tm|record_type|symbol|            event_tm|event_seq_nb|trade_pr|bid_pr|bid_size|ask_pr|ask_size|partition|\n","+----------+--------------------+-----------+------+--------------------+------------+--------+------+--------+------+--------+---------+\n","2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 09:34:...|           1|    NYSE|    75|     100|    75|     100|        Q|\n","2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 09:40:...|           2|    NYSE|    77|     100|    79|     100|        Q|\n","2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 09:50:...|           3|    NYSE|    77|     100|    77|     100|        Q|\n","2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 09:57:...|           4|    NYSE|    79|     100|    80|     100|        Q|\n","2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 10:06:...|           5|    NYSE|    78|     100|    78|     100|        Q|\n","2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 10:11:...|           6|    NYSE|    79|     100|    80|     100|        Q|\n","2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 10:17:...|           7|    NYSE|    77|     100|    78|     100|        Q|\n","2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 10:23:...|           8|    NYSE|    78|     100|    79|     100|        Q|\n","2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 10:31:...|           9|    NYSE|    77|     100|    79|     100|        Q|\n","2020-08-05|2020-08-05 09:30:...|          T|  SYMA|2020-08-05 10:37:...|          10|    NYSE|    79|     912|  null|    null|        T|\n","+----------+--------------------+-----------+------+--------------------+------------+--------+------+--------+------+--------+---------+\n","\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">+----------+--------------------+-----------+------+--------------------+------------+--------+------+--------+------+--------+---------+\n|  trade_dt|             file_tm|record_type|symbol|            event_tm|event_seq_nb|trade_pr|bid_pr|bid_size|ask_pr|ask_size|partition|\n+----------+--------------------+-----------+------+--------------------+------------+--------+------+--------+------+--------+---------+\n|2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 09:34:...|           1|    NYSE|    75|     100|    75|     100|        Q|\n|2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 09:40:...|           2|    NYSE|    77|     100|    79|     100|        Q|\n|2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 09:50:...|           3|    NYSE|    77|     100|    77|     100|        Q|\n|2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 09:57:...|           4|    NYSE|    79|     100|    80|     100|        Q|\n|2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 10:06:...|           5|    NYSE|    78|     100|    78|     100|        Q|\n|2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 10:11:...|           6|    NYSE|    79|     100|    80|     100|        Q|\n|2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 10:17:...|           7|    NYSE|    77|     100|    78|     100|        Q|\n|2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 10:23:...|           8|    NYSE|    78|     100|    79|     100|        Q|\n|2020-08-05|2020-08-05 09:30:...|          Q|  SYMA|2020-08-05 10:31:...|           9|    NYSE|    77|     100|    79|     100|        Q|\n|2020-08-05|2020-08-05 09:30:...|          T|  SYMA|2020-08-05 10:37:...|          10|    NYSE|    79|     912|  null|    null|        T|\n+----------+--------------------+-----------+------+--------------------+------------+--------+------+--------+------+--------+---------+\n\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["spark_df1.limit(10).show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"27b72e00-a82e-48a6-afd0-6d15e7802ca8","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">+----------+--------------------+-----------+------+--------------------+------------+--------+------+--------+------+--------+---------+\n","  trade_dt|             file_tm|record_type|symbol|            event_tm|event_seq_nb|trade_pr|bid_pr|bid_size|ask_pr|ask_size|partition|\n","+----------+--------------------+-----------+------+--------------------+------------+--------+------+--------+------+--------+---------+\n","2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 09:38:...|           1|  NASDAQ|    78|     100|    80|     100|        Q|\n","2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 09:46:...|           2|  NASDAQ|    77|     100|    77|     100|        Q|\n","2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 09:52:...|           3|  NASDAQ|    79|     100|    79|     100|        Q|\n","2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 09:58:...|           4|  NASDAQ|    76|     100|    77|     100|        Q|\n","2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 10:07:...|           5|  NASDAQ|    77|     100|    79|     100|        Q|\n","2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 10:15:...|           6|  NASDAQ|    79|     100|    81|     100|        Q|\n","2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 10:22:...|           7|  NASDAQ|    78|     100|    79|     100|        Q|\n","2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 10:29:...|           8|  NASDAQ|    76|     100|    77|     100|        Q|\n","2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 10:35:...|           9|  NASDAQ|    76|     100|    78|     100|        Q|\n","      null|                null|       null|  null|                null|        null|    null|  null|    null|  null|    null|        B|\n","+----------+--------------------+-----------+------+--------------------+------------+--------+------+--------+------+--------+---------+\n","\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">+----------+--------------------+-----------+------+--------------------+------------+--------+------+--------+------+--------+---------+\n|  trade_dt|             file_tm|record_type|symbol|            event_tm|event_seq_nb|trade_pr|bid_pr|bid_size|ask_pr|ask_size|partition|\n+----------+--------------------+-----------+------+--------------------+------------+--------+------+--------+------+--------+---------+\n|2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 09:38:...|           1|  NASDAQ|    78|     100|    80|     100|        Q|\n|2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 09:46:...|           2|  NASDAQ|    77|     100|    77|     100|        Q|\n|2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 09:52:...|           3|  NASDAQ|    79|     100|    79|     100|        Q|\n|2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 09:58:...|           4|  NASDAQ|    76|     100|    77|     100|        Q|\n|2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 10:07:...|           5|  NASDAQ|    77|     100|    79|     100|        Q|\n|2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 10:15:...|           6|  NASDAQ|    79|     100|    81|     100|        Q|\n|2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 10:22:...|           7|  NASDAQ|    78|     100|    79|     100|        Q|\n|2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 10:29:...|           8|  NASDAQ|    76|     100|    77|     100|        Q|\n|2020-08-06|2020-08-06 09:30:...|          Q|  SYMA|2020-08-06 10:35:...|           9|  NASDAQ|    76|     100|    78|     100|        Q|\n|      null|                null|       null|  null|                null|        null|    null|  null|    null|  null|    null|        B|\n+----------+--------------------+-----------+------+--------------------+------------+--------+------+--------+------+--------+---------+\n\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["spark_df4.limit(10).show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"177092e4-3672-4b66-a506-a84f5ed35088","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">+---------+\n","partition|\n","+---------+\n","        Q|\n","        T|\n","+---------+\n","\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">+---------+\n|partition|\n+---------+\n|        Q|\n|        T|\n+---------+\n\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Check the distinct partition\n","spark_df1.select(\"partition\").distinct().show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"4fe6fa29-ef11-4393-ac0b-2c0a2d2c6401","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">Out[9]: 300</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">Out[9]: 300</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# check the total rows of spark_df2 data frame\n","spark_df2.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"34555775-33d6-4c0d-81fc-5b66bc307dbe","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["union_df = spark_df1.union(spark_df2)\\\n","                    .union(spark_df3)\\\n","                    .union(spark_df4)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"154541df-2c9c-4e4b-98ad-d77113cbfe69","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">Out[13]: 1200</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">Out[13]: 1200</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Check the total rows of union data frame\n","union_df"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"78bfa4c8-c88f-443b-abd4-9fff7ed2b5bd","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">+---------+\n","partition|\n","+---------+\n","        Q|\n","        T|\n","        B|\n","+---------+\n","\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">+---------+\n|partition|\n+---------+\n|        Q|\n|        T|\n|        B|\n+---------+\n\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Check the distinct partition\n","union_df.select(\"partition\").distinct().show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"adc2c5a7-8844-4838-b47e-30b3dce7767f","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Write The Common Events Into Partitions As Parquet Files To HDFS\n","union_df.write.partitionBy(\"partition\").mode(\"overwrite\").parquet(\"output_dir\")"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"data_ingestion","notebookOrigID":2211900603944734,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
